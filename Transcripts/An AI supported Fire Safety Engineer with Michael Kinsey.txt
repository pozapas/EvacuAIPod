 Hello everybody, welcome to the Fire Science Show. Today's episode is all about the newest internet craze, that is the Generative AI or Natural Language Processing AI. You've definitely seen stuff about chatbots and like everywhere on the internet. And today we're going to bring it into the Fire Science Show. I've triggered this by sending a newsletter somewhere in December about possibilities with Generative AI in fire safety engineering. And I had a very nice response from Dr. Mike Kinsey, who actually has some real-life experience in implementing chatbot systems in fire safety engineering. So I've invited Mike to talk it over to finally have someone with hands-on experience on including those tools already in a fire safety toolbox. So in this episode, we venture with Mike into developments he did or he led in Arup, China in his time in there and how they've implemented this response query chatbot technology to their everyday's work. It's very interesting that such tools have already been employed, and we also go quite deep into how could we employ them better in future. So it's one futuristic episode, and I really hope you like it. So let's spin the intro and jump into the episode. Welcome to the Fireiresize Show. My name is Wojciech Wigrzyński and I will be your host. This podcast is brought to you in collaboration with OFR Consultants, a multi-award winning independent consultancy dedicated to addressing fire safety challenges. OFR is the UK's leading fire risk consultancy. Its globally established team has developed a reputation for preeminent fire engineering expertise, with colleagues working across the world to help protect people, property, and planet. In the UK, that includes the redevelopment of the Printworks building in Canada Water, one of the tallest residential buildings in Birmingham, as well as historic structures like the National Gallery, National History Museum, and the National Portrait Gallery in London. Internationally, its work ranges from the Antarctic to the Atacama Desert in Chile, and a number of projects across Africa. In 2023, OFR will grow its team and it's keen to hear from industry professionals who want to collaborate on fire safety futures this year. Get in touch at ofrconsultants.co.uk. Hello, everybody. Welcome to the Fire Science Show. I'm today with Dr. Mike Kinsey. Hello, Mike. Hi, how's it going very good good to see you in the podcast again there has been some stuff happening in your life you seem to be back in the uk how was the trip back home yeah great um yeah a lot's been happening uh move back to the uk change positions in a different role now and different company and yeah but really good really really good to see you. I'm really happy. So, Mike, I've invited you here to ask you one important question. Will ChatGPT replace Fire Engineers? Yeah, ChatGPT is really being a lot of popularity and discussion. Really interesting question, I think, for Fire Engineering and the Fire community. We've been playing with ChatGPT a lot, and I know a lot of people have been playing with it, fascinated by it. It seems to be everywhere over the internet. For the last months, everyone was I was hyping it. I was hyping it in my newsletter. Then you've reached out to me that you have some experiences with actually employing chatbots or this, let's say, out to me that you have some experiences with actually employing chatbots or this, let's say, how to call it, even language processing AI, I guess. So if anyone's unfamiliar with chatbot GPT, it's an open AI tool that literally is a chat window where you ask questions and you get answers from an AI that has learned the internet. It's quite general purpose. And the deeper you go, the, let's say, stupider answers you get. But also a lot of people have found a lot of value in that. So maybe let's start with that, Mike. I guess you were, I assume you were playing. You look like a guy who would play with chatbot GPT. So I assume you gave it a try. What's your experience with this AI? Has it blown your mind? Yeah, it has. And I think because I have had experience, a bit of experience developing chatbots for fire engineering, it kind of at the time we were choosing, you know, deciding what to do with chatbots and in fire engineering. And I think probably thinking about it fundamentally, chatbots are essentially a way to find information. But they use the interfaces, mimics like a conversation, dialogue between, you know, a computer or a system and a person. And if you think about the large majority of human history, that's how we gain information. So we almost have an affinity or a familiarity, at least, or bias towards wanting to get information through conversations. And I think the really neat thing about chat GPT is the broad spectrum of information that it can talk. It can give the illusion of talking about. I won't say talk about because, as you may know, it doesn't know what it's what it's telling you. It doesn't understand what it's spitting out. It's all about pattern recognition. But surely most chatbots technology are focused on closed domain problems where it's highly focused on specific queries and responses. Open domain chatbots about a wide range of topics, whilst they've been around actually decades, they've actually been pretty rubbish. And they fall up really quickly. Whereas chat GPT has had a much more resilience in terms of being able to consistently give reasonable results. But it's not always giving reasonable results. I wonder what was the difference? Maybe it's the scale of the training set they've used or maybe a different technology. I have no clue about the interior of the chat set they've used or maybe a different technology. I have no clue about the interior of the chatbot GPT, but it definitely felt a lot more chat-ish than the other chatbots I've seen. And it clearly could do a lot more than the ones that I've played before. I found it's really useful when you start giving it your own data to work with. I've tried it a bit with the podcast, actually. I was pasting him or it. Everyone's annoyed because I refer to Chad with this him for some reason I do not understand either. I was pasting it parts of the transcripts of episodes, and it was writing me a brief summary of what was happening in the discussion. And I found that, wow, that's really powerful that it can take a very random chat between two people because we don't use grammatical structures. Our sentences are not perfect. Anyone who ever worked with the transcript of spoken language and tried to turn it into written language, it's a difficult work. So it's very imperfect. And this tool, when supplied with such a transcript, it immediately was able to provide an interesting outcome. And actually, listeners, you can try it. There's transcripts of podcast episodes. Just go to the website, copy a part of the transcript, pop it into ChatGPT and tell it to summarize what has been said above. And you will see. So I found that mind-blowing that it can work like that, which is way beyond, you know, this information query that you've mentioned. It's not only finding information, but working with information. That was the part that brought my mind yeah absolutely i think um classically most most chatbot technologies in use today from like you know your banks um query response they're based on retrieval based systems so basically the way they work is you ask a question it then looks for similar questions in its database and then gives it a score and then what's the best scoring. And then it gives you the answer associated with it. So question and answer pairs. Whereas chat GPT kind of uses generative based responses where it's actually using language based models. It's learning from it and then it's outputting stuff, generating stuff from what it's previously seen before. And it's had a pretty good success rate, whereas in the past, it was typically these types of models were not very successful at giving incredible answers. You cannot ask questions about FHIR strategies to your T-Mobile assistant or whatever you're having there, which handles your issues or disputes about payments. Anyway, you've mentioned, and that was the reason why you've lured me into this episode, you've mentioned the FireChat GPT. And I was astonished when you showed me some little pieces of information about that. And it seems when you were in Arab China, you've been working on that well, well before the era of chatbot GPT. So it's not that you're falling on the newest trend, but it has it seems to be a long lasting process. So tell me a bit how you've seen the use of a chatbot as a tool that could support the engineer. Yeah, so when I was in China and I was thinking about, well, what couldn't we use chatbot technology to help us access information within fire engineering? And when you think about the large majority of what a fire engineer does, it's respond to queries. And I'm thinking, how can I make my life easier with this? And you can't just send reports saying the answer's in here. But what if we had a chatbot which could at least in some way in some context mimic fire engineer responding to clients and that's where it could have came from and I'd heard a bit about the use of chatbots retrieval based system chatbots in other domains like online in China they use Taobao but that'd be Amazon and it was amazing how well the chatbots would work on those types of systems. Like, for example, I could look at a certain train and go, do you have this in size 11? And it said, yes, we have it. Do you have it in blue? Yes, we have it. Really useful. In a chat window. In a chat window. It's all automated. And they would save, and there were thousands and thousands of people asking these and getting good hits. And there were moderators to them to help improve them. And I was thinking, why couldn't we use this for fire engineering? So that's how the idea came about. And then I teamed up some others in Arup. So there was Lil Wun, who was leading the programming and development. And then there was V.S. Sankar, who's a director in the Arup Hong Kong office. And together we looked at developing FHIR code chatbot. And the intention was that the chatbot, you could ask it a question about the FHIR code in China, and then it would give you the answer. We also played about with looking at FHIR strategy chatbots as well. But we mainly focus on the FHIR code chatbot. And then we started to develop, we developed a system in using Microsoft Cognitive Services, Azure's. And actually, it's fundamentally a very simple system in terms of the underlying technology of the chatbot. It's a query and answer system, which is basically a very simple database of questions. And then for each question, you have an answer. And you could have multiple questions for one answer as well. There's more than one way you could ask a question. So what would be a question you could ask to such a chatbot? Like, hello chatbot, I'm building a warehouse in Guangzhou and I would like it to be 100,000 square meters. What fire resistance class my walls should be? Like these types of questions? Exactly. So, I mean, fundamentally, if we think about a fire code, there's a list of requirements. So, those are the answers we want the chatbot to give. And then we have to kind of like the Jeopardy game, come up with the questions for those answers. Like what is the fire resistance of my high-rise building? What is the maximum travel distance in a place of assembly? Those types of things. So what is the answer based on? Is the answer based on the code? So would the chatbot have comprehension of what the code is and how different parts of the code interplay with each other? Or is it just a repository of good answers that fit the question? It's very simple. It's a retrieval system of trying to match the question that a person asks and then provides a given response. And just like chat GPT, which is a generative-based system, it doesn't know what it's giving you. You're just trying to define the logic. And both chat GPT and our retrieval-based system use NLP, natural language processing, but they use them in slightly different ways. So the retrieval system, when you ask it a question, it will then compare your question with all the other questions and answers in your database and then give it a score, you know, between zero and 100. 100 is, you know, absolutely the same as what we've got in the database and normally it would be in between. If the score, and you can define these thresholds, but if the score is above 80, we'd say that's a pretty good hit. Here's the answer straight away. If the score is, we define these arbitrarily just for test purposes, but if the score is between 40 and 80, we would then say, is this the question you mean? We'd ask for a clarification. And if the score was below 40, we would say, oops, we don't know the answer to this. And that became one of the interesting things. How do we manage uncertainty? And one of the and also scalability, because we couldn't exhaustively write in every single way of asking a certain question. So one thing we wanted to do was how could we grow this database using crowdsourcing or something like that? And one of the things was when scores drop below 40, we'd ask them, we don't know the answer to this, but would you like to enter the question-answer pair? And all they'd have to do is select the relevant section of the FHIR code, type in their question, and then it would go to a moderator panel, and then someone would check it and then update the database. So the idea is it hopefully improves the chance of scalability of these retrieval-based systems. So in the end, it's not that the chatbot technology known the FHIR code, it just known a hell of good answers to questions related to FHIR code and was just able to quickly match the best question to the best answer it had in its database. Exactly. That's exactly it. I wonder if we can reach the level where it could actually comprehend the code. I wonder if it would be necessary. So how did you build the database of the answers? Because, okay, Arup China is a big engineering company, so I assume you had access to a lot of expertise in there. Was it your learning set or you've done something else? So as I mentioned, it was kind of like a series of questions and answers. So the answers are all straight from the fire code. We can put those straight in. But the questions, we soon found out that you can't just ask someone off the street, can you just enter the questions in for these? You have to be a fire engineer to know the question you would ask. So we found that I couldn't just go and, you know, get a totally fresh graduate and go, please write the questions for these because they're just not experienced enough. So that was one thing we learned. Another thing we soon learned was after we developed it and we started prototyping and doing some verification tests, chatbots are only going to be as good as someone who knows the right question to ask. And one thing you realize is that there's a blank page in front of a chatbot. Whereas if you give someone a fire code, they're getting given information and that's feeding into what questions they need to ask. And this is one of the things with chat GPT. If you don't know the right question to ask, you're never going to find out the information perhaps you need to know. Maybe you need some sort of wizard to guide you through asking questions that could actually work. Yeah, absolutely. So we found that probably chatbots have got their place in very specific situations. When you're exploring something, when small scale stuff, high level stuff, very simple answers, possibly in building design, in the concept stage, where you're asking fairly simple questions. But when you start getting into very detailed questions, perhaps in the detailed construction phase of a building, then they're perhaps going to have challenges in giving you the level of detail you need in your responses. Let alone anything you ask, you have to be able to validate it later on after by asking a fire engine. And to follow on this question-answer model, when you were generating questions to your answers, was it like a manual work? You had to invent questions for a given clause of the code, or you related to some previous experience and just had a bunch of questions and just assigned answers to them? It's really interesting how to build up a training set for such a tool. We did it in a fairly brute force method. We had a team of engineers and we split up the code and say, can you write the questions for this? And you write the questions for this. I mean, thinking about it, what we're talking about here is one question, one answer. But really what we found was that a number of users would ask a question, but they wouldn't include all the information in their question for the chatbot to give an answer. Because often there's criteria you need to, if this, if this, if this. So one thing we implemented was follow-up questions, whereby if the chatbot recognized a certain chain of questioning, it would then ask you some clarifying questions and then it would give you an answer. So, for example, if I said, what is the fire resistance of my building element? Then it would ask you, well, what is your building type? And then what is the class of your building? And then here is the answer. So the question answer script, let's say, had a certain information pieces that were necessary to match the question to an answer. And if it lacked, for example, the area, height, location, something very obvious that's necessary to give an answer, it would ask a follow-up, please give me more information because it's unclear. That's brilliant. Exactly. And one thing we found was that basically any FHIR code, if you have a table, you've got at least two, you've got three questions you need to ask. One is the question that gets you to the table. One question is which row in the table you want. And then the next question is which column you want. So we developed an automated way to where a user could just copy and paste a table and then it would do an Excel script and then make the question chains to put that into. That's called a three-level question chain, I guess. We did that. That was quite useful. But it's by no means, you know, it's not doing anything that intelligent, really. It's not like chat GPT, but it's, you know, using existing technology to get you somewhere. It's the early days. You have to walk before you run. So it's interesting how the next generation could work and I already love it. I mean, I'm torn internally because what you have just described, there are people earning their living hood by knowing which table to look into. There are people whose lives depend on the fact that they are the ones who know in which table to look. And here, you propose a very simple way to make this feature kind of obsolete, because there is no advantage, competitive advantage, if there's a simple tool that you can ask the question, and it will figure out which table we're talking about, and then it will ask you for clarification about the data in row, and then we'll give you an answer. But on the other hand, is table seeking the most interesting aspect of fire engineering? For me, it's definitely not. And the world of fire engineers, there is a lot of fire engineers whose lives are literally filled with consulting tables and writing repetitive texts for repetitive buildings. This is a part of a job, which I would guess is not the most exciting one. So if you can put this technology into use for your benefit to do the boring part of your job, then maybe you have more time to do the boring part of your job, then maybe you have more time to do the exciting part of your job, which is conceptualizing fire strategies, for example. That is a brilliant outcome of this technology, I think. That was one of the main motivations for doing this, to make it some of the more mundane code lookup stuff easier, or possibly even give it directly to clients. That was one of the things we thought about, you know, perhaps in bidding stages where not all clients can afford to pay you to help you support a bid. But if you gave them access to a chatbot, they could perhaps get access to some information. But I think, like I mentioned before, one of the challenges we found was it relies on you knowing the right question to ask. And that's one of the things which certainly not all people who might use such a chatbot might know. When this whole thing with chatbot GPT came out and people realized the chatbot can code, because the chatbot GPT can code, actually. And it's like I wanted to pull a joke on it. And I told it, OK, chatbot GPTpt write me a code how to start a fluent simulation with python and then uh run a cfd and take the temperature profile from fluent and then plot it somewhere and the damn thing wrote the code and i felt oh my god there actually exists a database for that and it actually knew the database that That's crazy. And so people were starting, okay, are programmers obsolete now? Because Chatbot can program. And some programmers said, you know what, that means the clients would need to know what they want, which is definitely not the case. We are living in a world of abundance of knowledge, but it's the question part that's being difficult. If you can answer a very good question today, you can most likely Google an answer. You don't need a chat with GPT to find you an answer. But I think the power is in guiding you through your question, you know, in guiding you with the refinement of your question. Because if you ask wrong question in Google and get a hundred of incorrect results that are not aligned to what you were looking for, you may not have the feedback necessary to improve your query. Whereas if you have a chatbot GPT or chatbots in general that can guide you through the question asking process that helps refining your queries. And I assume your technology was not learning as it was using the users, right? But next level stuff could learn actually and improve itself. Or was it improving? It does use natural language processing in the sense that it was assessing the question you ask to the questions and answer in the database. And we did have a system whereby a user can say this is the right answer. So it would give us confidence that these are the right question answer pairs. But yeah, I mean, going back to one of your original questions, will chatbot technology replace code consulting fire engineers? And I would hazard a guess and say, no, but they will become a tool which fire engineers use to gain access to information. And it's the fire engineers that can use these tools that are going to perhaps replace the people that don't use such tools. That's a massive, massive competitive advantage, right? That's brilliant for sure. What about the hardware you need for these types of implementations of AI? Like, can it run on a laptop or at some point you need a these types of implementations of AI? Like, can it run on a laptop? Or at some point, you need a specialized supercomputer? You've mentioned you were using Azure Cloud, if I got it correct. So at what point the hardware is becoming a very important aspect of whether you can apply this AI tech or not? I think for prototyping, you can run a lot of things just on nothing more powerful than, say, a laptop. you can apply this AI tech or not? I think for prototyping, you can run a lot of things just on nothing more powerful than, say, a laptop. Anything which is just doing text-based processing generally doesn't need huge amounts. Or if you do, you can easily get fairly affordable cloud-based services to do analysis. So Microsoft Azure's cognitive services have a lot of free stuff. They have a lot of free chatbot services, free image analysis services, which you can get access to for prototyping. And if you think you find something which works, then you can start scaling up and then thinking about, do I need access to high performance computing? analysis of image data, that sort of stuff is going to start getting pretty memory intensive pretty quickly after small scale testing. But the small prototyping on smaller samples, like a laptop with a GPU should be enough, right? Can be. And a lot of my experience in looking at various different problems, yeah, absolutely, it can be for just testing out things. I find this aspect really intriguing because, again, I can go back and relate how CFD was developing, how CFD and FHIR was implemented. We have brilliant CFD fluid models for FHIR for a long, long time. And you still see papers in which someone would say, oh, I had to change my mesh to this and this size because it took a week on my laptop. And I'm like, oh my God, this is like this craziness because you shouldn't sacrifice the quality of your research due to lack of resources. I'm not saying you should not do the research, but you should do it properly. Like I'm not going to stop a fire resistance test in the middle of it because the gas is very expensive nowadays. The resources are necessary for good research and sometimes it's a lot of resources. I wonder, will we reach the point in development of AI technologies where people will start saying I didn't have enough resources to make this trained on one million samples so I just trained it on a 1,000 and what consequence to the quality it brings. Because I think here, the consequence would be actually much higher than me changing the mesh resolutions in my CFD. I think high-performance computing now is pretty, you know, almost cheap as chips. You know, anyone can pay for a hugely powerful server. You think decades ago, if people could do that, it'd be really difficult. I'd say probably the time-intensive stuff is not through processing power. It's through learning how this technology works, which takes time. And I think that's where probably a lot of the time can be spent. But once you've learned that, then the other stuff should, in terms of performance and processing, shouldn't be too bad. I really hope that is the case. I'm also fascinated, I know you're not that involved in this technology, but I'm also fascinated by BIM checkers, like the tools that can be employed in BIM models to quickly assess, for example, travel distances like you've mentioned before in the episode. And it seems like, again, automating a very mundane task that fire engineer would have to go and perhaps even manually. You know, I was drawing these lines. I was measuring this. It was done by hand. If you fancy engineers do it other ways, I envy you, but I've done it by hand in my life. I envy you, but I've done it by hand in my life. So I wonder, like, automating this task and then merging it, perhaps, with a code compliance checker, like a drawing generating a query to the chatbot or whatever low processing technology there is to, like, list you. Does it fulfill the law? And if not, which clause is being broken and what consequences are there? I see huge, huge challenges in automation like that. Yeah, absolutely. With BIM, in theory, you should be able to automate like almost everything or a large majority of a lot of fire code requirements. But from what I've seen, the devil is in the detail. And seeing how there's such a variety of ways people build their BIM models, which can trip up certain automation algorithms, which has created some challenges for doing this. There are certainly a lot of companies who are talking about automating things like travel distances, widths. That should definitely be possible in theory. But the devil's in the deep i think with a lot of it at the moment but i'm surprised you know i think people like uh autocad they are looking at this kind of stuff um but i'm surprised it hasn't taken off more easily um and allow if it could be you know finalized then it would allow fire engineers to focus on the you know the more heavy lifting of thinking about things like fire strategies and things like that. I'm also thinking about the conceptualization stages of projects where you would try to find the best outlook of the building itself. I had this episode with Ben Ralph in here, who's with Fosters. And he said that they would go through an insane amount of iterations, you know, like 10 iterations a day per building. And you cannot apply fire engineering to 10 iterations a day. There's no fire engineer that can do that, especially if you would expect some more fancy tools like even CFD modeling done to solve some issues. No way you can do it at that quickness. And with automation, this mundane task, you could have actually 10 iterations and a quick auto checker. Which of this iteration feels that the goals of fire safety objectives of the buildings that you have predefined and have this working along. Like if there are generators of layouts of the buildings inside and I've seen them in the Internet, like you literally just have a space and you click it to build your layout of your household. Why are we purchasing flats that have already an overlaid layout on them? Just sell me 60 square meters of space and just let me iterate through 10,000 of variants and pick one that I like in the end. It's not possible today because you would have to check the code compliance. You would have to check whether it feels for the requirements. So it's not very feasible today because there must be a human that would verify that. But if we get a really good code compliance checkers, this could be automated. That's the whole future there. Yeah, I think you've hit a very important nail on the head in the sense that how much reliance can we place on this? And is it going to be a case that the software does the automation, but then they didn't give it to a fire engineer? Please check it anyway. Yeah, I was about to check what was the role of moderators in your trial run with the Chinese chat code? With the chat? Yeah. Yeah, exactly. So the reason we had that, because we recognized scalability was potentially going to be an issue, we couldn't possibly think of all the questions for all the parts of the FHIR code. So we had a system that said, if you don't know the answer, but would you like to add the answer? And then they can add the question-answer pair. They would select which bit of the FHIR code, here's the question. It would then go to a moderator panel, and then a moderator senior engineer would say, yeah, that's the right question-answer pair. I would update our database. And then, yeah, that's the idea of scalability for a retrieval-based system. Okay. Let's go further beyond chatbots. We had a chance to briefly talk about AI. We both seem to be enthusiasts of new technologies, so it's always fun to talk. I had MZ Nasser on the podcast, so maybe you know him. He's a brilliant structural engineer from US, and he has some sort of magical sense. I actually think he's an AI algorithm. I don't think he's a human. But whatever he touches, he applies AI to it and it works like magic. And I wonder, are there problems in FHIR that are untouchable? To what extent AI can be applied? Because at this point, I see people dropping AI on literally everything. Like you can take a first paper you see on Google writing fire engineering and add with machine learning at the back of it, and it's going to be a valid paper somewhere. So I wonder, like, what's the range of capability of this AI tech? Or maybe we're overdoing it. Yeah, absolutely. So I've got, as you mentioned, I've got a bit of experience helping manage an internal AI project incubation initiative within East Asia, within Arab previously, looking at AI and not just fire engineering, but a range of different disciplines. And there are a few interesting things I can sort of speak to in terms of this. I would first say managing hype. There's a lot of people who are in charge of funding things, and they don't necessarily understand the true applications. So they're having to take a leap of faith. It's a bit of a black box stroke. AI can solve anything, and that's definitely not the case. There are certain problems which AI is very well tailored. Certain types of AI are very well tailored towards, but there are certain types of problem which is not very well tailored towards. So managing that expectation. Secondly, quite often you don't know whether something's going to work until you actually do it with, you know, specific AI technology. It's highly sensitive to the type of technology you choose, the data you have available, things like that. So there was an element of entrepreneurial risk taking when you say, please fund this prototype AI project. And that's something that we tried to do. We kind of tried to try and do rapid prototyping of lots of small scale AI projects, see what would work. And it very much followed the mentality of fail fast and fail early and fail cheap so that we could, you know, spread that and see what was going to work. Managing the expectations of the engineers doing the projects, because often they would sometimes oversell and sometimes they would have a good grasp on reality. And sometimes it's this is going to be the next, you know, Google or something. Well, maybe let's try it out and go from there. I see this now applications applications are fairly quite narrow. I cannot imagine a general purpose AI solver for flows in fires. In a sense that it can solve any fire in any configuration, in any space, with any boundary conditions. I can see an AI solver fit for, let's say, tunnels. AI solver for tunnel fires and with this magnitude of fire, with these boundary conditions for this size of tunnel, this shape of a tunnel. And it could be first. It actually exists. Xinyan Huang is doing amazing things, and his team are doing amazing things in tunnel space. But this is a very narrowly defined application for a specific problem. Now, the question is, do we really need an AI tool for solving tunnel fires where we have one-dimensional models at the same time? That's a separate question, which I'm going to ask in a few minutes. But it seems you need to very narrowly define the application because I hardly see providing these tools as general tools. Like that's the exact thing that made ChatGPT such a spectacular success because it was in a way a very general tool, not a very narrow tool, which we've seen fading in the past. But how do you feel about this generalization of the technology? Well, I think, first of all, all the applications I've experienced with, and I think probably most of the low-hanging fruit with AI, is highly focused on specific problems. Finding those problems is almost an art in itself, I would say, because quite often you can throw AI at problems which don't actually exist. So one of the things we try to sort of mentor and teach some of our engineers in the past is about problem hunting, finding problems which are fit for purpose for using AI. And generally we would say, you know, think about how does this problem, you know, save time, save a client or yourself time, money or do something novel which brings value to someone somewhere. money or do something novel which brings value to someone somewhere and that was sometimes one of the things where you'd say i can let let's say they i've got an ai model that predicts you know how fire is going to spread um that is really interesting um but you know when i think about commercial setting maybe what i don't know 10 of projects we work on actually use fire models and we can run a cfd already. You know, is it doing it faster? Well, OK, it saves a few days. Is that a big enough problem for us to solve? So that was one of the things, managing expectations about and trying to find the right problem. And what we found was certain disciplines or certain areas of disciplines were more ripe for throwing AI at than other areas. So where you have lots of data, where you can validate what you're doing is correct or not correct without doing huge amounts of work in the background, that was certainly one of the areas we found. And also when you're doing high-level explorative stuff is something, another area that we found was quite ripe for applying AI at. I had this example in my head that, I mean, if you have a shape of a square and the shape of a circle inside and you take out the circle out of square, you can actually calculate the area of square and take the area of circle from it. You can write some fancy integral or you can write a Monte Carlo model that will experimentally measure the surface of your square. Like, it's not about getting a better answer. It's about increasing complexity of your solution leading to the same answer. And I also see this type of activities in fire science as a reviewer of papers. I very often see very fancy tools, AI tools, different neural networks and machine learning uses employed to very simple engineering problems for which you already have answers for. The same was with CFD. The exact same thing was happening when a general purpose code, FDS, was implemented into the market and everyone started using it. And suddenly people stopped using zone models because it was so simple to run FDS calculation and it looked better. And it gave more believable answers than a zone model where you could just solve the zone model. Maybe you could just solve an energy balance equation on a piece of paper and get a very similar answer. But everyone was using CFD. I wonder to what extent AI-based technology will become the CFD black box of the future, that people will just go because it's the new fancy thing to do. I think black box and explainability, which I know your previous guest, I mean, Atia, has written about, is a real thing. And then that follows on to the where does validation and verification lie? You know, how much? And it goes back to are we solving a problem that is commercially is it big enough when we can run these models you know do a black box in AI versus a model which I can run and and anyway do I need to use AI to do this in a commercial setting but I think more generally when AI gives you an answer how do you know if it's real or not and managing that uncertainty is an important question that you know if it's real or not um and managing that uncertainty is an important question that you know we need to ask in the fire engineering community i think you here you touched a very sensitive thing the commercial setting i think that's the the element of the puzzle that many scientists actually lack they don't have this commercial let's say, background in their head. They don't think in terms of how much money time you can save, what problems you can solve that are unsolvable. Many people would say, okay, we're going to save 30% of time by employing them. That's sometimes not very much. That's sometimes not worth the hassle. And we already have this in existing projects. Saving money is also some sometimes not enough like think about structural fire engineering we know very well how to make very optimized structures from the fire performance point of view but in many cases you would not go there because it's just so much quicker and easier to just go for a specific fire resistance and over design it a little bit but at least it's approved and it's the and scientists would think okay this is amazing we're going to save time and money well in not all cases this is worth doing this is why what you've mentioned with problem hunting hunting problems is is it's really interesting especially that you can find solutions for many problems like uh i've said before. Whatever you seem to apply these technologies, if you're narrow enough and you're able to match the AI model to the problem at hand, you probably will get a fairly decent solution. It's not with AI algorithms anymore. It's about matching the problems, their severity to the needs of the market, and matching these with the specific solvers, right? Yeah, I mean, this is one of the reasons we chose to look at FireCode chatbot because every building we use a FireCode on, we don't use modeling evacuation structural CFD models on the large majority of the projects. So this was very much born out of a bit of problem hunting. projects so this was very much born out of a you know a bit of problem hunting i mean one thing i would touch on as well is when we're using ai um one thing we used to tell the engineers is it said look this is the first time you're doing ai you're going to find it difficult you're probably going to fail and it may not work and it's about teaching them a bit of humility saying it's okay if it doesn't work we can learn from this whereas sometimes there's a belief that you have to promote success in everything you do which which in a normal project perhaps that is the case but in ai it's okay to fail as long as we can all learn from it and say look this didn't work because of xyz they you know it's very hard for not not let your ego creep in and um say you know actually it was a success when actually it wasn't. Yeah. And because your base of expertise is with human behavior, evacuation modeling, how is it in your world? Do you see a lot of employment of these technologies in this space? Are there any directions you think that could be interesting in development of AI-supported tools? I think in terms of existing studies and research, there have been some studies looking at exploring data and trying to infer things like decision models in wildland urban interface using GIS data, things like that, which is really interesting. There's been some stuff more recently looking at trying to anticipate crowd crushes before they happen using cctv footage so a lot about pattern recognition and feeding into what's going to happen next i think there's a huge area there's loads more that could be done but i'm aware also that we might be throwing problems at it which aren't there's hidden variables that we're not measuring in some of this work and you can make an ai model you can something called overfitting you can overfit an ai model and then someone says yeah it's a really good predictor but then you apply it to something totally different and it just collapses um but that that's not going to get you published um and it goes to something we recently mentioned on on twitter recently about publishing data which is showing your model doesn't work. I think that's a real issue about overfitting in some of the stuff. But I really hope that AI can be used for things like decision making, which is like a whale of a subject in evacuations, which is really hard to look at. And from researchers' perspective, like counting people, making trajectories and stuff like that, I guess it can, again, take a lot of mundane tasks from the researcher. You mentioned GIS, so that's Geographical Information Systems, right? So you use that to track people and track movements and hazards. Can you tell a little more about these applications? That's certainly not by me. That's certainly by Rogério at massey university and some of his team um and i think erica florida people okay don't worry exactly exactly um really interesting stuff but what i would say is um overfitting is sort of a question that's a bit of an it could be an issue with just looking at data and maybe there are variables which you're not capturing but that doesn't you know it's hard to you know it's how much are we really tapping it? How does it apply? I guess generally apply some of these models in different situations, which is hard to assess. Brilliant. So the final one, what about transparency of AI solutions? Like it's quite a general concept, you know, like even the chatbot. So anyone can build one. I wonder like to what extent we should have insight into how does it work like do we need to understand how it works to trust the answer that's probably the best way i can formulate my question yeah good question i think generally the chatbot can give you the wrong answer and then the question is how do you verify what you're being told is right or wrong? So I think generally the use of things like chatbot, even AI, should only be done by people who understand the subject matter. And the idea is it's used as a tool to get you to a solution or find something else fairly quickly. It can be used by perhaps less experienced people to explore different aspects. But you need to be very careful about relying upon it for a specific design, purely because it could give you the wrong answer. So I think if we tailor our level of confidence according to our level of expertise, then it can be used as a very powerful tool for doing stuff with. That's a space for well-trained fire engineers. Worst case, you're going to be a validator of the answers, and that's going to be a work that needs to be done by a human because we're touching very important aspects of fire design. So, Mike, we're not going to be replaced by AI, but it's better to get used to using them, actually, learn them a bit and find out if in your niche, if in your specification there are tasks that you hate doing and you may be better doing other stuff and just leave them the boring ones to the computers right yeah absolutely hopefully we can um i'm really i'm really excited to see what what people are going to start doing in this stuff and hopefully they'll start addressing challenges of problems which are mundane that can allow people in fire engineering to start focusing on the really complicated, interesting stuff, which is very hard to automate. Okay, Mike, thank you very much for coming to Fire Science Show again. It was as good as the last time. I really enjoyed that. And see you on the other end of ChatGPT someday. Cool. Thanks, Wojciech. That's it. Thank you for listening. A lot has happened since we did this interview with Mike because ChatGPT has been updated to version 4, which has impressively improved its capabilities to work. Now it can take longer amounts of text to work with. It can process more complex things. It seems to give better answers. ChatGPT also became a paid tool. Now if you want to use it and not get lost in the queue of people waiting, there's a shortcut by paying them money as a subscription. So that's a very interesting turn of things for an open AI company that suddenly became a very, very non-open and capitalist company. But I guess that's what it is. It's the most disruptive technology introduced in many years. So I could expect that it's going to be commercialized at some point. Anyway, Mike brought some very interesting insights into how their Chinese fire code built at Arup China was used, how they developed it, what problems they run into. And he gave actually quite a lot of information that could allow you to set up your own version. It's not chat GPT, it's responsive query on Microsoft Azure. So it's not going to be the same thing, but I guess the idea is very similar, and it's a nice starting point for development. So very worth trying, very disruptive technology, and I see a lot of future of tools like that to automate mundane tasks of Fire Engineer that none of us likes doing, but that need to be done. And maybe we can focus more on fire strategies and things that matter, things that which we have spent lives training for and that we're the best people on the planet to do. So that sounds like an exciting future. And yeah, AI is not going to replace engineers, exciting future and yeah AI is not going to replace engineers but engineers with AI will replace the engineers without one so let's get trained and let's get familiar with these tools that's it for today's episode as always see you here. Thank you for listening and see you soon.