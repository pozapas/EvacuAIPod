Introduction to publishing - EDK

Okay, welcome everybody to our second webinar in the human behaviour and fire series. This webinar is on how to write a good peer review for human behaviour and fire papers, and it's hosted by the permanent working group of the international association for fire safety science. 
Our permanent working group is human behaviour and fires, so we're very excited to be talking about this today, and the speakers I'll be talking about it, and I also, dr Peter Lawrence, will be speaking on this as well. 
So before we get into peer reviews and how to write a good peer review, I'll first give a little bit of background on who we are, and so the human behaviour and fire permanent working group of IAFSS is coordinated by Enrico Ronchi from Lund University and myself, and I am at RMIT University. I'm in Melbourne Australia. This again is our. second event in our webinar series. The first event was how why did my first paper? 
Why did my paper get rejected and this is available on our youtube channel if you want to take a look. We had editors from four fire journals to talk about how to write a good journal article. Our permanent working group is made up of 180 members, and we've established this to act as a coordinating body to monitor, develop and guide research on all aspects of human behaviour and fire. 
So we have a series of activities ongoing, one of which is the webinar, and we're also working on a research roadmap, and so our purpose here, especially this webinar, is to disseminate important information, especially to early career researchers, on how to produce quality research in human behaviour and fire and really how to thrive in our field. I'll talk about. 
In the very end of this, talk about our third webinar in our series on terminology and its use and misuse in the field, and also if you're interested in joining our permanent group of IAFSS. The link is there at the bottom of the screen and also can be shared in the chat as well. So who am? 
I am a vice chancellor, senior research fellow in the school of engineering at RMIT, so I'm in the civil and infrastructure engineering discipline within the school of engineering. My backgrounds are fire protection or fire safety engineering, ms and bs, and I have a phd in sociology as well. 
Prior to coming to RMIT, I've been here about a year, but prior to that I spent 18 years at the national institute of standards and technology in the US in their engineering laboratory, and there I was working on post. 
Disaster studies trying to understand the impacts of hazards on communities, and so my expertise and what I've been studying for gosh over a little a little over 20 years now is decision making and response behaviour of people under imminent threat, emergency communications and evacuation modelling, and I'm super excited to be joined by dr Peter Lawrence. He is a research reader in computational pedestrian dynamics in the fire safety engineering group at the university of Greenwich. 
He has backgrounds in mathematics and computer science and he's sharing with you today his 27 years of knowledge, and he's been working in academic research, consultancy and software development within fire safety engineering, and he has expertise and computational models for human behaviour in emergency situations. So what are we going to be discussing today? I'd like to first start off with talking about why this event? Why are we talking? about this. What is a peer review? 
Why does this matter and also get into the benefits of the peer review process? I'll get into how does the peer review process work and some things to consider when being asked to review, and then I'll turn it over to dr Lawrence to talk about how to write a good peer review and he'll go through a five step process. 
After he's done with that, I'll pick it back up again and talk about the characteristics of a good review and leave you with the reviewers checklist. We will both end this presentation with a set of open questions. So in addition to answering any questions that you have for us on giving writing a good peer review, we also have some questions for the audience. 
Maybe to spark a discussion, some kind of potentially con contentious questions around the peer. review process and it's interesting kind of in writing this and working on this with Peter. I've been well. Both of us have been doing peer reviews for quite a long time now, but it's been really interesting to kind of take a step back. 
Think about what is a good peer review, think about the process and so even those who have been reviewing for a long time. I hope you find this enjoyable. Maybe it's a refresher course and certainly will hopefully get your mind thinking when we go to those open questions at the end of our presentation. 


Why this webinar? What is a peer review? - EDK

So why are we having this event? So the last webinar was on it discussed you know a good journal paper right. 
Why was my paper rejected? How do I write a better journal article? So writing journal articles is difficult enough. But then we have the peer review. process right, and so it's a very important process. It's a process whereby experts in the field review our work right, review our article and provide comments to the editor as well as the author. So it's a productive and important process right. 
It's meant to ensure rigor in our field, the quality of our research. So it's extremely important and to succeed right you must share, but it might be intimidating to put our work out there. We all have to do it and because of that right we all have to submit our work to journals so it can get published so it can get out there. 
It's also expected of us that we review the articles of our peers right. So it's an important service right that we're giving to our field. However, it can be a pretty contentious process. So there's many memes flying around social. media too many. Actually, as you can see what I was having fun on the screen there. So there's kind of some memes about how frustrating the process can be. 
It doesn't have to be, but sometimes it can be, and I don't know if you've heard that this kind of hashtag going around reviewer number two, and so what reviewer 2 symbolizes is a peer review that is rude or condescending, maybe a little vague, inflexible and all other adjectives you might be able to think about regarding peer review. 
So think about this webinar as how not to be reviewer too, because all that does is delay the process, hinder or thwart your ability to get your great work out there right. The peer review is meant to facilitate the publishing of quality research and since human behaviour and fire is an interdisciplinary theme, interdisciplinary topic that attracts. researchers from all over many different types of perspectives and disciplines. 
We as human behaviour and fire researchers should be ready to review articles from a number of different journals, different topics, different focus areas. So here are a few examples of the journals that myself and Peter have reviewed for, anywhere from fire safety journals right we have some listed on the screen to disaster journals, transportation journals, as I'm kind of moving some of my research and evacuation from the decision to some of the other decisions that follow communication journals and journals kind of that are all over different disciplines. 
So we've put those kind of in the others right journal event journal of gis or the journal of computing and civil engineering, and Peter has also reviewed for mathematics and engineering journals right also computation journals, the journal of applied cognitive psychology, and so it's you. 
Know the fields that touch human behaviour and fire are varied, and they're many, and so it's very important that we think about what goes into a good peer review, as we're reviewing for all of these different types of journals, and so, even though at times it may be a difficult or potentially contentious process, like I said, it doesn't have to be, and there are many benefits of reviewing articles for journals. 


The benefits of reviewing - EDK

So first and I talked about this a little bit when I started if we can feel that it's an academic duty right to perform these reviews, and so I submit papers to journals and I'm asking my peers to review them, and I so I should do the same in response. But it also helps to strengthen papers in the field, and so just a few weeks ago I had with the team a safety. 
Science journal article published on evacuation, and I had four reviewers review that article and I am so proud of the results and they provided such amazing feedback and it really helped strengthen the paper. 
They asked for clarifications when it wasn't necessarily clear, because as an author we're so involved in the in the topic, we don't always know and not we're maybe not always able to take a step back, and the reviewers can help us to say: wait a minute. You haven't provided enough clarification on this topic. Additionally, we had reviewers from multiple countries right, so they're giving us different perspectives to make sure that I wasn't. 
This was a fire that we studied in the US, and so we weren't. Perhaps we were making assumptions that the readers understood about evacuation policy in the US right, and so they were helping us strengthen the paper. broaden our descriptions about evacuation policies in multiple countries, and they also asked for additional details on our limitations. They were giving us some suggestions on new research hot off the presses, and they also saw some benefits. 
So we had we used mixed methods and perhaps we were under playing right our methods. So they asked us to make sure that we made that clear, that we had a mixed method paper, and it's something that we should talk a lot more about. So at the end of the day it really did strengthen our paper. Was such a benefit right to have those four reviewers also doing reviews. 
Keep us up to date with the latest developments that help stimulate new ideas, as we're reading about new experimental techniques and also helps us to be aware of some of the latest research done by our peers and. it certainly is a learning experience. We have the opportunity which is not always the case right kind of maybe rarely the case to ask directly the authors questions about their article right to help clarify some points. 
And also extremely important, we're building rapport and association with journals, conferences, editors, beginning to be more and more a part of the human behaviour and fire community. 


The peer reviewing process - EDK

So a bit about the peer review process. It might be something that's kind of very obvious to some, maybe not to others. So I just want to kind of go through the process, make sure we're all on the same page about what are we even talking about. 
So the first step is that the associate editor or guest editor or the editor of the journal or one of the editors, sends the reviewer an invitation email right. Here's the abstract. Here's the. article title that we want you to review. Are you willing and able to review, and so at that stage it's up to the reviewer to accept or decline that invitation via the editorial system. 
Now, if the reviewer declines, then essentially their role is over, but they are asked to suggest other reviewers, and this is an extremely important process. So if you are a reviewer who doesn't have the time, perhaps or maybe this isn't an area, perhaps that you feel confident in reviewing the paper in, please consider suggesting other people, other experts in the field, to review. 
This is extremely helpful to the editor and make sure that there's still a quality review on the other end. Now I'll get back to this, but you could be asked to review again an r1 or an r2 if you decline. At that point it becomes a bit. 
Difficult for the editor right because as you're, when you're asked to review an r1, it's essentially did the author appropriately address my comments, and so it's not impossible for the editor to find someone to review your r1 or review that r1 or r2. But usually when I say yes to accepting a journal article as a reviewer, I'm also saying yes to reviewing the r1 and r2 etc. Hopefully there's not too many after that. 
So if I accept as a reviewer, I'm provided access to the paper. I'm giving my due date and the review is most likely blind right. So I don't know who wrote the article and the authors will not know who reviewed it. So as a reviewer, I'd read the article, I provide my comments, I actually write up my review and I make my recommendation, and I enter all of that into. the editorial system. 
If I accept it's likely, I'm not going to be asked to review it again if I reject. I'm also not likely to review that article again, but if I suggest minor and especially if I suggest major revisions with my comments justifying that decision, I will likely ask to review the r1. So things to consider when you're asked to review an article: do you have the right skill set? Do you have the time? 
This is an important one, because a lot of times we're given three or four weeks to review, and it's really respectful to get that review in on time. Right. You'd want the same thing if you were an author of your reviewers, and so if you don't have the time, it's helpful to think about. Okay, am I willing to make the time, or could I suggest others to do? it. 
If you maybe don't have four weeks but you have five weeks, go ahead and contact the editor and maybe they would still want you to review. Also ask yourself: is it of personal interest right? Because if it isn't, are you really going to give a quality review? 
You still should, but I usually do the best reviews when I have a personal interest and what this is all about, and I'm excited about reading it and also ask yourself: do you understand the scope of the journal and the com or the conference you're reviewing for? Because that will come up when you're asked about the relevance of that paper to the journal itself. 
So this is where I will stop and turn it over to you, Peter, to go through the five step process of how to write a good peer review. Okay, thank you, Erica. 


Step 1: Summery - PL

I'm going to take you through the process of actually writing up the review. So you've accepted the paper, you've gone through it and you've read the pdf or whatever you've been provided with, and you've made a number of notes. 
And you've gone through you make your notes, you've identified certain features about the paper, you found interest and then now you come to the stage of where you have to actually write that up and provide your feedback to the author and the editor. One thing to note is, when you write the feedback to the offer, it's actually also for the editors to look at, because they need to use that information to make a decision. 
So on many systems there's like a couple of different boxes which you, where you get to rate the paper, you get to provide the feedback to the author and you. get the feedback confidential information to the editor. So we've broken that down into the five step process and how to go through that stages involved in the review process. 
So when you start writing up your review, the first thing you got to do is write one or two paragraphs, summary up that paper and identifying what is its strengths and what's its weaknesses, and you need to highlight any major concerns or issues within the structural or mythology of that paper. 
And it's also good to write in the first section some general con comments on what's the key findings of the paper and its contribution to knowledge. And you think why should I do that? Well, it says demonstrate what you understand when you read that paper or what you believe the contribution to knowledge. I've read a number of papers where the authors are written down. 
And says this is the contribution to knowledge, where it's not actually the correct area, where they actually contribute. They actually contribute in a different area. There was something else for them or it didn't contribute to knowledge. So you need to make sure you know what that is. And also is there a clear research question, because often you can read a publication and there's no clear area of research or what object objective they are looking at. 
So what's the research question they're trying to address? If there isn't a research question, often there isn't any contribution to knowledge. So now on the next slide, I'm going to take you through some examples of how to write up that first paragraph. So Erica, next slide, please, right here we have a very short example of a write up now. This is our not so good example. This is. quite short and brief and it's not. 
It's quite vague. It says this paper, the topic of this paper, is of interest and importance, but it doesn't tell the editor where that's important, because they've got they're writing a journal and they would like it to fit in with that topic of the journal. So you need to specify this journal. This paper has certain areas of interest. It says it says it's well written in terms of logical clarity and precision. 
This is good because it's giving positive feedback to say what it is, but it doesn't say precisely what that is and then it does. The analysis section does not provide enough detail on the process or principle, something that could make the paper interest as a scientific contribution. Therefore, this newspaper needs to be improved now. If they just wrote, that's not enough, because they then would. 
Need to follow this, with the public points minor or major corrections. So if you go into the next one, it's very good. Thank you. So this one is a bit. This is us an improvement and this gives a bit more detail, and it says it uses some novel data from a particular event, develop several models to explain evacuation behaviour. And it says it's well written and it says it's one. 
It's structured and a solid literature review, which is good for the editors to know, because literature reviews are very important. Often papers lack in the literature review. They have some contribution knowledge but they often miss some of the background information. And then it says this how this folk can use some improvement, particularly in terms of its framing and discussion. And then it will go on to list a few. Okay, Erica, please next paper. 
Next term slide. So this is this is a better one and this one here. This is my final example. It says it prevents a wildfire evacuation simulation model to approach that attempts to account for the impact of varying vegetation levels during the summer months. So it says what the what it does, what it does, and then the manuscript cites appropriate background. Literature is clearly structured, includes well full out figures, and then he goes on. 
I feel the manuscript contributes to knowledge in the following areas, and that's important because if it's a research paper, it needs to contribute to knowledge. So and then you say my major concern with the manuscript relates to the frame of the approach taking its application. Furthermore, the discussion around a limitation and applicability of the results is very limited and the validity of some of the assumptions need to. be justified, and then he goes. 
I detail these concerns below. So it then follows on with those bullet points. So that's a very basic short a couple of examples. Often they're longer, but trying to fit longer examples on a slide is difficult, so I've kept it as brief as possible. 


Step 2: Detailed comments - PL & EDK

Okay, thank you, right. 
So once you've written the initial one or two paragraphs highlighting the contribution to knowledge and what's good about the paper and what's bad about the paper, you then need to give more detailed comments about the paper. So this is where you put it under the microscope. 
So you go through the paper and you look at your markup on your pdf or whatever, and you then take each of the bullet points and issues, and then you would write some comments about that, and so you can do this in several ways. on many systems. You can do as a list in a given order in the paper. So you just go through line by line saying or section. 
So you say section one, page two, line five or whatever, and then say a sentence. Then you list those things, including line numbers and pages. Or often people group them as major and then minor. So you group the major ones first, followed by the minor ones, and then you might put some recommendations after that. So you might recommend something changes about paper, but they're more optional, or if other systems will allow you to. 
If you mark it up in a word document or pdf or you've got a list in a word document, you can upload that directory to the website. So on the next slide I'll give some examples. So here we have some examples of detailed feedback. so here they'll be broken down into major and minor. So the first one says sentence to page two. This is starts questioning something about their model. 
So they've picked a fire, but there's some issue with the simulation fire data. So therefore the author needs to justify the use of such fire and modify the underlying or underlying model. Again. 
This is where it's sometimes difficult to make what's minor and model minor and major minor issue, because that could be a minor thing if they could justify it, but if they need to re run their whole simulation, that could be a minor ish major issue. In the second example it says page four largely please address these behaviours impacts on people's responses to the incident. 
The authors should explain in the paper, while the choice is made during the evacuation process, how individuals perceive risk and the. communication impacts their decision making. So that involves them providing more detail in the paper. And then obviously you've got the minor ones which are when they use colloquial languages. So words like has enjoyed great popularity. That's quite a vague statement. What do you mean by popularity? 
It could be amongst the press or the scientific community. So it's the sort of language that needs to be avoided in a publication, and there's lots of. If you search the internet, there's lots of information about what sort of language to avoid in papers and these will be minor changes you can make also check the references level are correct. So, for instance, I've seen it. You go along the read the paper. 
I find a reference that I'll have to check there and you find it's missing in the reference list and also you need to check they reference. the correct paper, because I've seen many papers where they might say: oh, panic is common in the field, and then they reference a paper that explains that panic is wrong term to use. I've seen it with stampede. 
They say we know we're going to simulate stampedes where they're actually going to simulate crashes. But they then reference a paper that talks about stampede is the wrong term to use and it should be a crush. So that's why it's very important to check the references in the languages and you would pick those up in minor changes. Okay, our next slide please. So this is Erica's slide. 
I think yes, okay, so just kind of some examples from our. You know our day to day. I'm. I usually review quite a number of data papers, and so these are some of the things that I've kind of picked. up on one related to terminology and so the use of natural hazards right. I would recommend, rather than natural disasters or, as Peter said, the term panic right. 
So that's kind of sparks and a red flag for me. So then I have to kind of comment a little bit on what did you mean by that? Is you know? Do you, do you mean how it's defined in this way or in another way? So it's important to pull out some of these things. With terminology related to theoretical foundation. I normally ask: well, what theories provide the foundation for this work. 
I'll point out if literature is lacking, maybe from the social sciences or from wildfires or from building fire fields, especially if the author may not be from these fields, I can suggest some literature that they may need to use as foundational for their study. or, and I'm also within this topic, focused on the gaps right. Where are the gaps in the literature and what sorry, excuse me what gaps in the literature are they trying to fill? 
And so yes, they've outlined a literature review. But next, what's missing right? What is their contribution to the field? And if that's not made clear, I'll point that out related to methodology. There's a lot right that I look for in data papers, the applicable, the applicability of experiments to reality. Right. If you've asked people to run as fast as possible, what does that represent? When we're talking about building fire evacuation? I'll ask: where's the ethics discussion? 
If I don't see one, why did you pick that sample size? If it wasn't clarified or if it wasn't discussed in the paper? And if it's small, then how does this affect the results any? issues with design, both qualitative and quantitative, is where I would kind of make some comments related to methodology in the results. I will pick up on things like: are these the appropriate statistical tests to use? What about qualitative results? 
Where are the themes? So a lot of times people authors may say that they're using qualitative methods, but then the results don't reflect that. And then what is the purpose of this result? So just because you, just because you can find the answer right, just because you can use your data in a way and provide this result, is, does that actually provide what an answer to your research questions right? 
So just because you can find the answer doesn't mean it's useful and then inaccurate claims of causality if they do that. And then finally, I look to see if papers make links back to. the literature right. So if they link their findings back with the literature that they discuss in the in their review, if they explain the differences right, why do you find this result? When the literature is finding something different? 
And then I look for limitations. I look forward to limitations, discussion something that's pretty obvious right, because not every study is perfect. I don't think any study is perfect. And then what are the practical implications of your work, if relevant? Okay. So I'm going to now talk about the modelling papers. What I look for in general modelling papers so obviously the first thing is what's the phenomenon they're trying to model? 
What sort of behaviour are they trying to use? Is it appropriate? Is it? Can it be modelled and then the terminology around that? So often they talk about verification of validation. Sometimes they muddle the. two up and then if they use any broad terms like I'm going to model irrational behaviour, then you need to define it. What do you mean by irrational behaviour? And it's the same with panic behaviour. 
Said you're going to be panic or the words stampede, and so sorry. Sometimes they get these technologies incorrect. So they say stampede when they mean a crush when they've got nobody running their way. So they're looking at crash behaviours and things like that. So that's what I'll have to look at. So they got a model. Have they described it in the correct terms? 
Are they using terms like verification, validation and appropriately and also the significance of the research in relation to other models? It's quite often you see a new automata model or a new social forces model. There's lots of them out there, so they need to be. 
Very precise about which of those papers they reference, so they make sure they're not reproducing, because there's so many different applications of social forces and other pedestrian models, and there's plenty of them out there. So they need to be very good about the background literature, because if that's incorrect, they can go off and develop a model that somebody else has already developed and therefore the contribution to knowledge is very weak. So it's very unlikely. 
The paper is going to be used and also other things is like: is the modelling system appropriate for addressing a research question? So they might be using an off the shelf games engine now there's no harm in that in itself, but is the games engine the background? They're supporting it because the game's engine has been built for games primarily, so it needs to be used in the appropriate way. 
So if they're using a games engine to look at smoke, people's behaviour in smoke or signage, have they used it in the appropriate way? Have they changed or adapted the rendering algorithms or the underlying models in there? Because there's lots of good things you can bolt onto these games engines, but if they use the off shelf, the standard ones, often they're not up to standards. So are they built on top of something that's appropriate? 
And also, if they're using a discretised space or and they're trying to look at crowd crush, can that model be applied to that? So does the modelling system fit the research questions, objectives that they set up and also it's about calibration. So they're trying to reproduce actual human behaviour. So that needs to be based on data. They talk about data driven models, so the model needs to be. 
Driven by the data and then and many times you see that they do one or two basic experiments and then apply it to develop a model, and they use many, many different parameters and they kind of over calibrate to a particular cases. So it gives great results for those cases they've collected data for. 
But can that be generalized to other cases as similar situations and then in discussion I have to look at what kind of model outputs will collect, what all data outputs are collected and if there's enough data points. So it's quite common. They say I'll run it 10 times, five times or six times and they give you an average and then they don't talk about what's the variable variability in the model. 
So I've seen them they run them 10,15 times and there's no variation between the simulations anyway. so they can just run it once or they run it 10 or 15 times and they quite a standard deviation of say 400 out of a simulation range time of a thousand. So is that appropriate? 
And I is there enough data points, enough runs, and there is various papers out there talking about how many simulation runs you need to do and how you evaluate your model and have they collected it for the appropriate data points? So, for instance, if they're calculating the number of people who use a particular signage system, yeah you don't want it to get enough mean on the simulation time. 
You want to get your convergence on this actual statistics you're collecting and also that brings me on what the results being compared to. Sometimes they will provide just a graph and gay simple inspection and say all these two graphs. look close or they may provide more advanced statistics now, simple visual inspection may be appropriate for a journal paper or if it's early research. But what I'm expecting a general publication is a bit more in depth advanced statistics. 
But even then some will just provide the statistics without providing any visual feedback, because there's numerous examples of where you get to accept. The statistic says this is good results and they are conversions, but then when you do some visual inspection of the data, it's way out and there's various examples. 
You can go on there where they show we can get low correlation with a straight line and the actual underlying distribution is like a dinosaur or something strange. And then what's important is what's the model limitations and scope on top of that. So once they've done all that, where's the limitation? What's this limited to? 
So if they're using a particular model, this model might be only applicable for collecting information on people how they respond in a certain event in a certain situation. So they might be collecting how somebody responds to a explosion on a subway or a tube train. So it's not actually looking at evacuation times. It's looking at the actual responses. 
So that's the scope of the model and then if there's any learning outcomes, and this is good as a scientist. What I'm looking for is what works and what didn't work. So it's nice if they write in the paper some examples. I might sometimes write this question. They don't necessarily have to answer the paper. Say you tried this technique? Did you try anything else? Did it work and it didn't work? So why did you? 
Why did you select the method you're using and that if? you can say: oh, I tried this and it didn't work and the reasons it didn't work. That's useful for me. Enough of research scientists and communities, but we don't reproduce mistakes of others. And then in the conclusions you've got to see if it's been substantiated by the research model. 
Now many occasions I've gone for the conclusions and I've actually written some of the conclusions that's not supported in the main body, or they might introduce some new information that's not mentioned in the new text. And then I would write this correction that you've written a statement. This needs to be substantiated in the main body of the work. 
So that's probably a minor correction, because often they can just go off and add something in the main text and then obviously further work. That's similar to limitations. How is this model going to be improved? How? do you take it forward? So I always look at what further work you say right? 
If I was a researcher who was coming along and I had to start work in this field, the further work section is really good for me, because that can tell me how to improve the model. So what do I need to what areas do I need to do further research on? How do I develop it? And that's kind of that wouldn't be a major minor correction. 
That might be a recommendation I might put this is I would. I would like to see a bit more further work in there, or this further work section looks a bit limited. I recommend improvement, but that's not like a deal breaker invite, correct? That's just a recommendation. I would put in a paper. Okay next slide please. 


Step 3: Confidential comments to the editors - PL

So now you've written up your. feedbacks the author and the detailed corrections. 
As I said before, that feedback's the office, not just for the author. It's also for the editor to read, so they can make a decision. At the end of the day. You may recommend major or minor corrections. It's the editor who decides whether it's actually a major minor or a rejection. So in effect, your write up is like a recommendation. It's the author. So for instance, you then go in the section in the website. 
It tells you about your critical comments, confidential comments to the editor. So you can use this space to mention any concerns about submissions. So this is not going to the offer. So you shouldn't use it to take the paper or the manuscript to say if there's issues or problems with it. You need to bring up other things that's not mentioned about. your concerns about submissions. 
But if there's something major about the concerns, for instance if you think it's in plagiarize or something serious, you should bring that up with the editor straight away before finishing your review. So you just say I've seen this. Send them an email saying: look, this seems to be an issue here. Do I need to continue this review? 
However, there's something a bit subtle or, for instance, you might have ticked it for minor corrections, but it's kind of borderline major. You might say that in the confidential comments, the editor you might say this paper I'll teach it is minor, but I think it might be major, but I can't really say for certain, and that helps the editor when they make the decisions, whether it's major, minor or to reject the paper later on. 
But so, and it also provides a space. for you to give your opinion on an article, so you. So often journals will give out awards or they like to know what's a good paper, what's a bad paper. So if they've got a lot to review, they might be selecting the best paper. 
So you can say: oh, I really think this is a good one and I think it's the best paper I've read in a long white time or something like that. So let's take me on to next slide, okay, please. So also in that section instead of the in, it's just the right written and section. 
There's also a number of bullet points that you may need to answer these examples from fire technology and as I mentioned previously, they have a tick box which you could also mention is in the confidential comments. The editor is has the main material, please being. published elsewhere? If so, where? So you might have seen something similar research somewhere else. This needs to be brought to the attention. 
Often it might be you might just see in a journal paper. So the editor needs to know that is this essential new information from that journal, from the conference publication for the general publication? So no often scientists would publish part bits of the work together somewhere else, in conferences, places like that, and then they will bring it later on together to be a general publication. 
And then there's questions about are the experiment, statistics, models or procedures appropriate that you can answer inadequate, except or really exemplary, but that should be reflected in your feedback, the author, so you can't say they're inadequate when your feedback is very little information about the actual mythology. So that should be consistent with what you write and. 
Then are the conclusions and the findings meaningful to the fire safety and community, and I think that's more for the journal to make the decision whether it fits within the scope of the journal when you say it's inadequate, acceptable or exemplary. Okay. So here I give an example of a possible feedback to the editor, where you're kind of you've read a paper. 
It seems good, but there's something slightly wrong about the method or the technique, but you're not too sure about it and you might have written something to the in the comments to the all first to say the case and they could answer it quite simply. So there's some kind of possibility of selection bias when you're looking at it and you might have asked that question. 
So if it's if it's if it's, if it's not a problem and they can answer and. the off the authors can answer it in a satisfactory way. That'll be very minor correction. They might be a small change to paper, but if they've committed some bad, there's some really bad statistics. They would then have to go off and redo all their statistics and re evaluate that well. 
That would make it more major corrections or, if it's really bad, that could actually turn into a rejection. I've used the term p hacking because at the moment this is. I've picked this example because there's a big debate about using the p value and whether journals should use it and about this in the scientific community anyway. But it's just a simple example to say: look, it looks like a problem with the paper I picked. 
It's minor, but it could turn into major corrections. 


Step 4: Recommendations - PL

Okay, next slide please. So at the end of this. before you press the submit review submit button on your review, you need to make sure it all adds up and looks consistent. Like when you're writing any paper or any article, you need to go back through it to make sure it meets the expectations. It's consistent. 
So if it says: accept the paper as it is, it shouldn't be a load of major revisions required or a lot of minor revisions. So as except as is doesn't necessarily mean there's any, there isn't any issues with the paper. There's just issues that could be picked up when they do the proofing of the paper later on in the proofing stages. So if there's just a few minor grammatical errors or etc. You can accept it. 
As is minor revisions is there should be at least at least a number of minor revisions for it to be accepted? But nothing major will show up and again with major visions, it should list a few major revisions and then but however, if you select to reject unless it's really bad, you need to explain in your comments to the author where the fundamental flaws are and whether you're large emissions, because it's about, as Erica said early on, review process is about bringing papers up to standards. So even though the paper's been rejected, you should it's. It's. 
It's a community kind of responsibility to try and help others in the field and help them improve their papers. For instance, papers I've rejected have often had issues with literary review and I can provide some areas say they need to look up these areas and understand that particular area of the research domain and these discussion points we're having in the areas. So this feedback should be in there. 
If you're rejecting, so that when the person gets it back, they get some real good feedback. And sometimes when I submit papers, I like it, even if they reject. I think if I get some feedback, I think good, because I can use that to improve what I'm doing. Or do I know whether I'd know long this research isn't needed and I'm taking a dead end route. 
So that's why it's always good to provide feedback, and here we get the last. 


Step 5: Review the revisions - PL

Well, point five is certainly, if well it's not over. Once you press submit, you're likely to get a paper back if you've got minor or major corrections, and then you need to go through how the authors address them and see if they addressed them. 
To address your questions to the level you expected of kind of are acceptable, but it's important to keep an. open mind. Because you're not writing this paper, you need to say: have they addressed? It's an appropriate scientific standard? Are they meeting what's required? Are they meeting the essential requirements of your comment? So you're not writing a paper? It's not your paper. It's somebody else's paper. 
And have they met those requirements within a flexibility that you're allowing for that? And then so you go through and you tick them off, and it's quite often they haven't addressed all your comments in detail. You might they might have explained something but maybe not made changes to the paper. 
They may change something and they're added to it, and then you've found additional mistakes or questions you need to ask, so they might have written a new section and who rewrites their literature review but still miss something out. So you then take that and you feed that back. 
Into the system where you say that's the thing, and so there's still some that you say something like yes, they have object, except to say the majority of my concerns, however these who are still remaining. So you would then list those ones and go for a similar process. You did before, but the feedback will be shorter. 
You just list the ones they haven't addressed and you say why they haven't addressed them, and then you go back again and it'll be initiative process where the paper will go off the authors. There are just your concerns again and comes back again and eventually you'll hopefully get to the accept button right clear connect side. 


Conclusion & checklist - EDK

So this is your okay, yeah. So I will take it from here and take a station. 
So thanks, Peter, and so good peer reviews are clear, kind, constructive, fair and consistent and. so clear. We want to be able to make sure that the authors understand what we're saying. If you want them to make a change to the paper, then say that if we're just asking questions, then that's okay, but really we should be asking questions for them to then make revisions to the paper if needed kind and constructive. 
Obviously we want to not be reviewer too, but fair too. Let's set our ego aside. I often wonder if other reviews that I've seen maybe the reviewer was threatened by the work right, and so that's where some of these kind of prickly comments came from. 
Set the ego aside and provide a fair review, because for the at the end of the day it really does, as Peter said, raise the standard of work and publications in our field, and also don't nitpick, and Peter talked about that. should be the author's papers. So we're ensuring quality here. Right scientific merit to ensure that published work is grounded in sound science. 
It's okay to say you don't understand something, not necessarily our role to then rewrite it right. So it's the author's paper. We shouldn't be nitpicking style right if it doesn't help, if it doesn't really provide the way to get it to sound science. Right to a quality paper. Provide feedback that the authors can use to improve their study. 
Highlight what's good about the manuscript boy does that feel good when you get that review back and it starts off with what was good about the paper. That's fantastic. It's a really nice way to start and then identify what's novel about it and its significance. Right and next I have to tell myself next slide and then also important to justify our recommendations with. concrete evidence and specific examples. As Peter mentioned. 
It's not good enough, as the meme says, to say this paper is meticulously researched, but I don't recommend it for publication. Right, we don't want to be that reviewer. It's important to identify possible limitations or gaps in the literature review or the methodology and ask yourself: are you comfortable signing your name to that review I have put I have written something. 
Maybe I was a little crab aptly, or I didn't have enough dinner or something, and I reread my comments. I said no, I would not want to sign my name to this and then you know a lighten your tone right. So just make sure that you're asking yourself these when you're, when you're before you submit your review and then make sure it's detailed enough right to help the editor make their decision we put together. 
A little reviewers checklist just kind of gives you a summary of all the great things, hopefully great, we just talked about anywhere from. Am I the right person to review? How do I begin my review? What should the detailed comments include? My comments to the editor. You know those types of things. Do my comments match the recommendation? Am I really willing to review again? 
So take a look at those check boxes to make sure that you have them all before you hit submit. And there's also. Peter found a really nice detailed checklist that goes through maybe some of the stuff we didn't talk about yet and some additional considerations actually of each section of the paper they go through. So for the title, does it clearly express what the manuscript is about? 
For the abstract, is it short and a clear summary of the? aims, key methods, important findings and conclusions. Some examples from their detailed checklist about tables and figures. So is, are the data presented in a clear and appropriate manner? Do the figures and tables include measures of uncertainty right? So these are kind of important questions we need to ask ourselves to make sure that our reviews are complete and then references. 
Are there places where the authors cite a review paper where they should have cited the original paper right? So the detailed checklist I recommend if you're kind of thinking about: do I have everything? We have a more general checklist. 
The detailed checklist helps you to go through sections of the papers, make sure that you have everything you need, and also they have peer review checklists for if you're reviewing systematic reviews, methodology articles, review articles and the like, and so key takeaways. Reviews are essential. right, so they're essential for the development of sound scientific research in our field. 
So I want to thank all of the reviewers who are listening for all your hard work and increasing the quality of human behaviour and fire papers in our field, and it doesn't have to be this kind of bludgeoning you know process, as we have in the cartoon here. 
If we think about how we submit our reviews and we have the right goal in mind, then it can be a very helpful, beneficial process, and we wanted to leave you all with some open questions that we kind of debated a little bit when we were thinking about how do we want to put this presentation together and what should we talk about so? 


Open Discussion

Well, we pose these to the audience right and we don't have to cover them all today, but if you. find one that you're particularly interested in. So first, how do you decide between minor and major corrections? Right, how do you decide between those two? And Peter gave a great example of sometimes we write the editors and we say in those confidential comments: I'm kind of on the fence right. 
I'm on the fence between major and reject, and so you know if the other reviews come back in a certain way I could go either way. So how do you approach the issue of grammar in English? We have a lot of experts in our field whose English isn't their first language or their second language. 
I mean really impressive people who are who have who know several languages, and so how do we approach when we when we talk about the need to review for grammar in English and what is the appropriate language that we? should use in our reviews. Should you collaborate with others when we're viewing and when we talked about collaborate? 
Peter and I we're like what do we mean, and so if you just broadly talk about a method, for example at a at a broad, more general level with a colleague, is that is that something that you should do? Or should you keep everything to yourself and review just within your own kind of personal knowledge? 
What counts as an apparent conflict of interest like, yes, the journals likely account for that and have rules on that, but are we do we know of those rules and are we following them, and what does that mean for a reviewer and one that seems to be kind of hanging around the twitter sphere is, should reviewers sign their reviews, and I thank Max Kenneth for bringing this up to Enrico? and myself. 
They're pros right transparency being able to actually ex exchange some information between the reviewer and the author, like during the process or even after. So they're pros to signing your reviews. And then there are some cons, right. What if it actually causes some lasting potential issues between colleagues in the field? You know what are the pros and cons and should we be signing our reviews? 
Some people do already, but it's not standard practice and a lot of people don't. And finally, should reviewers be paid for their reviews right? I have a little comic there that kind of highlights that question. So I want to thank you, Peter, I'm sure wants to thank you for your attention today and wherever you are in the world listening to us, but what I'm going to do. 
Please write if you have any questions or comments or. You want to start a conversation on a good peer review, please feel free to reach out to me, but I'm going to go back to this open questions for further the discussion, but before I do, I think I would be remiss if I didn't just introduce the next webinar, in case you have to leave a bit early, and it is from experts, dr Milad Haghani and dr Anne Templeton, on the misuse of controversial terminology and evacuation research. 
So that is in February, the 8th of February. I really hope you can make it for that one. That's going to be an interesting one. So what I'll do is I will go back to our open questions and open it up for any questions you might have already asked in the chat or if anybody wants to kind of turn their video on and say what you. how you're feeling about what we just talked about. 
So thank you so much for your attention. I look forward to the discussion. So what I'm going to do is I'm going to at least kind of get out of this, so I can see the chats. Can you guys? Hopefully you guys can still see the open questions. Oh, we just have some hellos at the moment. Oh, and thank you, Arthur, for sharing the forms with us. 
If you want to sign up for either you know the group itself or for the next webinar. But please maybe raise your hand or just chat or just you know, start. There is a question. Okay, there's a question. So to what extent? This is from Alastair Shipman? To what extent should reviewers be checking? Are known references for plagiarism? What extent should reviewers be checking unknown references for? plagiarism. 
So Alastair, what do you mean by unknown references? Hi, yes, sorry, thanks a really great talk. Thanks. So, basically it my kind of thought process is: I'm reading a paper and I'm just going to assume that all the references that this person has cited is: are you know correct and they haven't copied and pasted wholesale? 
I mean there are checking systems and I'll know a few of the references, but I definitely won't know all of them. Yeah, to what extent is that kind of under control? Yep, so great question. A lot of times when the editor gets the article, they'll see the percentage of the paper that's like other and anything available really in journals or online. 
So that gives the editor a sense of what is the percentage of this paper that's actually original. So I don't really think it falls on the. reviewer really to check for that. It really should fall on the journal, the editors. Obviously, if you see something that sounds familiar to you, I do think that it's within our responsibility to check that out, right to go a little bit further to see if we were right. 
Oh gosh, this sounds exactly like something I read, but I don't think that the responsibility per se falls on the reviewer. For that. I don't know if Peter you have a different perspective than I do, but that those are my thoughts. Yeah, the responsibility probably doesn't form the reviewer, but it's worth doing what you can and mention anything. 
If you notice something that's been from another paper, another general conference that's been used, it's worth pointing out. So when you say check unknown references, are you saying check the reference list as well as that? Yeah, so. I mean I use and I think quite a lot of people will use some form of latex bibliography. 
So in terms of making sure the references are actually present in the bibliography, that much is automated, but then checking those references for say, for instance, this person has cited x 2011 and x says that this is a fact like do I would I then be obligated to read x 2011 to check? That's what they say? Well, I wouldn't say that you're obligated to do. 
It's just sometimes when you've got experience in the field, the other viewers, you notice his references and you think they say certain statements and you think. Well, this doesn't feel correct. I need to check that reference. So the reference is interest. So you should, you can make a reasonable effort. You don't have to check everything. You just say oh. I've read that this statement looks a bit unusual, and I know that all for they're referenced. 
Does that fit with what they're saying? And that's what? For me it's just my experience in the field. I can look at these and I can say: oh, I can see that reference. And if I don't recognize the reference, I'm often curious to say: oh, I need to go and look at that one, because I haven't read that paper. 
And then I would go and have a look at the abstract of that paper and then say: oh, that abstract doesn't match up. So you just a reasonable level of scan through it, I think, is often enough. We're just picking up some really bad ones. Obviously the summer will make it out. I've often seen often read published papers and you go along when you look at the reference. 
They're made is incorrect and I saw on twitter they mentioned somebody wrote an article about panic and somebody used it as a reference to say panic and people clearly panic in emergency situations, but the actual paper, the actual reference they use, was saying the opposite. So as a review, you just try to make a reasonable effort. You can't go into. You know spend all day on it and months and months working on the paper. 
You've got a limited amount of time. So it's about making a reasonable effort or work on the paper, and that's why, when we mention that you only take a review on if you've got enough time to do it, because you need to take some time to look it and read through, and that's why I often I don't accept from journals that says: oh, I want you to turn this. 
Around in three days, because I just don't feel I can do a decent review in three or four days. But there seems to be a lot of pressure on reviewers to turn around. Thank you for that question. That was a good one. We have more questions, Erica in the chat. Oh cool, okay, thanks, Enrico. 
So there is one from Michael Kinsey on automate basic level English checking to have a minimum level before it gets passed on to reviewers. Yeah, now that's a good question, mike, I don't know the journals that I have been a part of. I don't think they do that and I don't know I don't know if they have. 
If they, if they all you know, have the ability to do that, but I don't know I mean it's a. It's a tough one because if you pick out a lot. of issues. The paper might still be really fantastic and have amazing content. It just needs to be read by. You know needs to be reviewed by a technical editor. Yeah, just for me it's like. 
The key thing is the English to the standard that I can understand what the objective of the paper is. So if the grammar is really bad, but can I still get from that information what they're trying to do? Yeah, and the background literature supports that. So it has to be. It hasn't doesn't got to be perfect. It's got to be enough that it's understandable and that's the issue. 
So it's just get up to that level where I can understand it enough to ascertain whether there's a contribution to knowledge in that paper and the method is unique. I see mikan muting himself thanks. I think that was some really. good feedback. 
I guess one of the kind of things that I commonly see is because so many papers coming out of china and I often get a few and I maybe I'm more prone to it than other places. 
But I just thought maybe there's an opportunity for automation here and maybe having some formal guidance of what to do when the English isn't good enough because the typical thing is, please get a native English speaker do it and then I've got to find one, or you know, maybe there's some opportunity to have some formal guidance. 
No, I think, absolutely great point, mike, I think that's a really great point and I mean something that I'll take back to Guillermo from for fire technology and I don't know. Maybe I don't want to put Enrico on the spot, but safety science I don't know if they haven't. yeah, I think, because there is sometimes I know editor in chiefs they do that kind of screening. I think we discussed it even with Bart last time. 
So generally what he was mentioning that I mean we don't have really a scientific approach with this. But sometimes when the language is very bad, that's also correlated with not the so good paper, if you know what I mean. But it's not necessarily the case. It's true, it's not. It's not always the case, so it's it generally goes more like if text and figures and other things like are sloppy and so on. 
Then it's not a good start, especially for journals which are very competitive in terms of success rate of an acceptance rate of papers. That is one of the discriminants that immediately popped up in the eye of the editor in chief to basically best reject. the paper. So if you have a journal with 10 or 20 percent acceptance rate, those papers there almost never gets to reveal. But it's might be exceptions. 
They may be very good because they are simply not so well written. So it's not always the case. Enrico, maybe we could take. I know that there's some, but maybe we can take one more and then we'll probably have to. There is one more question, because the other one they all relate about English and la saros. Some comments. So one comment there is from Joo Almeida. Hi, nice to see you. 
One major problem is the urge to publish it, then it costs many master and obviously phd students must publish some research might be not of the best or ultimate discover, but good enough to be shared. Perhaps some distinction papers of top quality and others just to. accomplish the obligation to publish. This is one comment. So how do we deal with papers that are borderline? Let's say yeah, I think that's a great question. 
I mean I'm gonna throw it over to Peter to see if you want to start. Well, as you know, you submit a paper to a particular publication or a conference or journal and it may not be accepted. But there's different platforms for publication. They accept papers at different levels, so it might not quite meet the standard for a journal paper. 
You would probably try for a conference or a referee conference for that, so it's actually targeting your publication at the right level. Now this push to publish. That's a different matter, and you know it's not good really putting pressure on scientists to publish, and it's a sad fact now that people are pushed to publish more papers. 
Than they need to for us in the UK, we only need to publish four papers for the ref cycle for good quality. So desire to publish a lot of mediocre papers is less you. We want to get four good quality papers over a certain time period. So the important things for us is the quality of the research with the paper. But yeah, I can't answer the question about being pushed to publish. 
That's really an issue for somebody else to answer. But you bring up an excellent point, especially for phd and master's students, who's whose thesis are the papers right that they've published, and I think it's, you know. I think it's it definitely can be an issue. Peter, you bring up a good point about different platforms for publishing. I mean I think the same thing for within our field. Some journals have higher impact. 
Factors than others and have higher. You know different standards and it's just finding the right one, and also you know how you're packaging the new research. It just has to. It has to be a good, you know contribution to the field. Just because you're not finished can still be a good contribution if it's framed in the right way. So it's not an easy question to answer, but thank you for posing it. Excellent question. 
Thank you if, if I may, I was just trying to point out that sometimes there are different types of research that might be of quality enough to be published. I mean, obviously, as you said, Erica, there are master students and phd students that might be cutting edge or state of the art quality work to be published, but sometimes there is a urge or a need to publish and that could. 
Be in some way stated in the paper itself, meaning that this is a kind of a research that is okay. It's just a kind of a proof or doing something that has been done several times before, as you were saying a while ago regarding the social forces, for instance, there are so many work redoing over and over and over again the social forces from elving and okay, it's nice research but it's not cutting edge. 
So my point here is if there was somehow a way of distinguish between papers that are of relevance and papers that are just academic papers that are okay papers, but not top of the or top notch. I'm not. I'm not sure if I was clear, but perhaps paper journals and eventually conferences should distinguish between papers of top quality and papers of, let's say, a second level or. something like that. Thank you so much. 
Oh, thank you for your comment. All of the comments give us quite a bit to think about when we're not just reviewing, but on editorial boards and associate editors and such. So, thank you. Yeah, and as was thinking, that's a question of how do you bring your research up to the standards? Because you know if you push to publish, you might be rushing it. 
You need to get your work out there as early as possible so you can get as much feedback as possible. So you need to share your ideas with others and communicate with others, and they will give you feedback to improve your research and hopefully that will bring your research up to standards. So if you're doing work on social forces, you need to share that in the community, at other conferences, workshops and places. 
Like that get feedback in your work so you know how to adapt, to adjust it, to meet to obtain something that's novel and interesting, because people say hey, nobody's tried this, or I know lots of people have tried this, so it's talking to other researchers will help there. Well, I want to thank everybody for joining us. 
I see that there's some things still in the chat, but I think probably for now we'll close our session and thank you so much for joining us and for listening. We will be posting this to the working group youtube channel so that if people weren't able to make it today, hopefully they can see the recording. And yes, please look forward to our next webinar in February on terminology. 
How relevant, since we were talking about that today a little bit so. Thanks, Enrico, for doing the q a. for us and thank you all for joining us, and thank you, Peter, for co presenting this with me. It was really fun. I enjoyed it. Thank you, okay, everyone. Thank you so much. Thank you bye, everyone bye. 